{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "INL-lab5-crf-NE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gEUqyX-57bY"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygJ8d4Pt57bZ"
      },
      "source": [
        "!pip install sklearn-crfsuite"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hhJHjJA57bZ"
      },
      "source": [
        "from itertools import chain\n",
        "\n",
        "import nltk\n",
        "import sklearn\n",
        "import scipy.stats\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtEDkjGe57bZ"
      },
      "source": [
        "## Let's use CoNLL 2002 data to build a NER system\n",
        "\n",
        "CoNLL2002 corpus is available in NLTK. We use Spanish data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svFtHlM357bZ"
      },
      "source": [
        "import nltk\n",
        "nltk.download('conll2002')\n",
        "nltk.corpus.conll2002.fileids()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ny195Sh57bZ"
      },
      "source": [
        "%%time\n",
        "train_sents = list(nltk.corpus.conll2002.iob_sents('esp.train'))\n",
        "test_sents = list(nltk.corpus.conll2002.iob_sents('esp.testb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e14GPlth57bZ"
      },
      "source": [
        "print('wielkosć zbioru treningowego:', len(train_sents))\n",
        "print('wielkosć zbioru testowego:' , len(test_sents))\n",
        "train_sents[10]\n",
        "# opis znaczeń tagów: https://freeling-user-manual.readthedocs.io/es/latest/tagsets/tagset-en/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdSGvwFf57bZ"
      },
      "source": [
        "nltk.help #używany w nltk tagset angielski"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFOhUrhz57bZ"
      },
      "source": [
        "#proszę wylistować wszystkie występujące w zbiorze treningowym tagi (2 kolumna) i etykiety (3 kolumna)\n",
        "labl={}\n",
        "tagl={}\n",
        "for s in train_sents:\n",
        "    for w in s:\n",
        "        try:\n",
        "            labl[w[2]]+=1\n",
        "        except KeyError:\n",
        "            labl[w[2]]=1\n",
        "        try:\n",
        "            tagl[w[1]]+=1\n",
        "        except KeyError:\n",
        "            tagl[w[1]]=1\n",
        "#labl=sorted(labl)\n",
        "#tagl=sorted(tagl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj86Obog57bZ"
      },
      "source": [
        "print(labl)\n",
        "print(tagl)\n",
        "print(sorted(labl))\n",
        "print(sorted(tagl))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Pa3Dzhb57bZ"
      },
      "source": [
        "## Features\n",
        "\n",
        "Next, define some features. In this example we use word identity, word suffix, word shape and word POS tag; also, some information from nearby words is used. \n",
        "\n",
        "This makes a simple baseline, but you certainly can add and remove some features to get (much?) better results - experiment with it.\n",
        "\n",
        "sklearn-crfsuite (and python-crfsuite) supports several feature formats; here we use feature dicts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOOGT3OI57bZ"
      },
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][1]\n",
        "    \n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        'postag': postag,\n",
        "      \n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        postag1 = sent[i-1][1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "  \n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "    \n",
        "                \n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for token, postag, label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, postag, label in sent]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "462-f-xdbno4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "227e68Tg57bZ"
      },
      "source": [
        "This is what word2features extracts:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keY1TvcS57bZ"
      },
      "source": [
        "print(train_sents[0])\n",
        "sent2features(train_sents[0])[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoG61aIq57bZ"
      },
      "source": [
        "Extract features from the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_8oInu957bZ"
      },
      "source": [
        "%%time\n",
        "X_train = [sent2features(s) for s in train_sents]\n",
        "y_train = [sent2labels(s) for s in train_sents]\n",
        "\n",
        "X_test = [sent2features(s) for s in test_sents]\n",
        "y_test = [sent2labels(s) for s in test_sents]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIpwxULX57ba"
      },
      "source": [
        "## Training\n",
        "\n",
        "To see all possible CRF parameters check its docstring. Here we are useing L-BFGS training algorithm (it is default) with Elastic Net (L1 + L2) regularization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjKi-qiO57ba"
      },
      "source": [
        " #help(sklearn_crfsuite.CRF)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7r2IBUf57ba"
      },
      "source": [
        "%%time\n",
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs', \n",
        "    c1=0.1, \n",
        "    c2=0.1, \n",
        "    max_iterations=100, \n",
        "    all_possible_transitions=True\n",
        ")\n",
        "crf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UUuCykj57ba"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "There is much more O entities in data set, but we're more interested in other entities. To account for this we'll use averaged F1 score computed for all labels except for O. ``sklearn-crfsuite.metrics`` package provides some useful metrics for sequence classification task, including this one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oer93-BM57ba"
      },
      "source": [
        "labels = list(crf.classes_)\n",
        "labels.remove('O')\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgzEwgTj57ba"
      },
      "source": [
        "y_pred = crf.predict(X_test)\n",
        "metrics.flat_f1_score(y_test, y_pred, \n",
        "                      average='weighted', labels=labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEAKRvNa57ba"
      },
      "source": [
        "Inspect per-class results in more detail:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTnTuYPd57ba"
      },
      "source": [
        "# group B and I results\n",
        "sorted_labels = sorted(\n",
        "    labels, \n",
        "    key=lambda name: (name[1:], name[0])\n",
        ")\n",
        "print(metrics.flat_classification_report(\n",
        "    y_test, y_pred, labels=sorted_labels, digits=3\n",
        "))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhJ4Y42J57ba"
      },
      "source": [
        "## Hyperparameter Optimization\n",
        "\n",
        "To improve quality try to select regularization parameters using randomized search and 3-fold cross-validation.\n",
        "\n",
        "I takes quite a lot of CPU time and RAM (we're fitting a model ``50 * 3 = 150`` times), so grab a tea and be patient, or reduce n_iter in RandomizedSearchCV, or fit model only on a subset of training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xq7R3_HR57ba"
      },
      "source": [
        "%%time\n",
        "# define fixed parameters and parameters to search\n",
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs', \n",
        "    max_iterations=20, \n",
        "    all_possible_transitions=True\n",
        ")\n",
        "params_space = {\n",
        "    'c1': scipy.stats.expon(scale=0.5),\n",
        "    'c2': scipy.stats.expon(scale=0.05),\n",
        "}\n",
        "\n",
        "# use the same metric for evaluation\n",
        "f1_scorer = make_scorer(metrics.flat_f1_score, \n",
        "                        average='weighted', labels=labels)\n",
        "\n",
        "# search\n",
        "rs = RandomizedSearchCV(crf, params_space, \n",
        "                        cv=3, \n",
        "                        verbose=1, \n",
        "                        n_jobs=-1, \n",
        "                        n_iter=10,   #zmienione \n",
        "                        scoring=f1_scorer)\n",
        "rs.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8oH-5Lj57ba"
      },
      "source": [
        "Best result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNEoUJI457ba"
      },
      "source": [
        "# crf = rs.best_estimator_\n",
        "print('best params:', rs.best_params_)\n",
        "print('best CV score:', rs.best_score_)\n",
        "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XInzwy-57ba"
      },
      "source": [
        "### Check parameter space\n",
        "\n",
        "A chart which shows which ``c1`` and ``c2`` values have RandomizedSearchCV checked. Red color means better results, blue means worse."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhZH06UI57ba"
      },
      "source": [
        "_x = [s['c1'] for s in rs.cv_results_['params']]\n",
        "_y = [s['c2'] for s in rs.cv_results_['params']]\n",
        "_c = [s for s in rs.cv_results_['mean_test_score']]\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.set_size_inches(12, 12)\n",
        "ax = plt.gca()\n",
        "ax.set_yscale('log')\n",
        "ax.set_xscale('log')\n",
        "ax.set_xlabel('C1')\n",
        "ax.set_ylabel('C2')\n",
        "ax.set_title(\"Randomized Hyperparameter Search CV Results (min={:0.3}, max={:0.3})\".format(\n",
        "    min(_c), max(_c)\n",
        "))\n",
        "\n",
        "ax.scatter(_x, _y, c=_c, s=60, alpha=0.9, edgecolors=[0,0,0])\n",
        "\n",
        "print(\"Dark blue => {:0.4}, dark red => {:0.4}\".format(min(_c), max(_c)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_jCTjf557ba"
      },
      "source": [
        "## Check best estimator on our test data\n",
        "\n",
        "As you can see, quality is improved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NBIlXV357ba"
      },
      "source": [
        "crf = rs.best_estimator_\n",
        "y_pred = crf.predict(X_test)\n",
        "print(metrics.flat_classification_report(\n",
        "    y_test, y_pred, labels=sorted_labels, digits=3\n",
        "))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJ8y6HhL57ba"
      },
      "source": [
        "## Let's check what classifier learned"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fayHIt-57ba"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "def print_transitions(trans_features):\n",
        "    for (label_from, label_to), weight in trans_features:\n",
        "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
        "\n",
        "print(\"Top likely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
        "\n",
        "print(\"\\nTop unlikely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3RSBwEC57ba"
      },
      "source": [
        "We can see that, for example, it is very likely that the beginning of an organization name (B-ORG) will be followed by a token inside organization name (I-ORG), but transitions to I-ORG from tokens with other labels are penalized.\n",
        "\n",
        "Check the state features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mfaCAzl57ba"
      },
      "source": [
        "def print_state_features(state_features):\n",
        "    for (attr, label), weight in state_features:\n",
        "        print(\"%0.6f %-8s %s\" % (weight, label, attr))    \n",
        "\n",
        "print(\"Top positive:\")\n",
        "print_state_features(Counter(crf.state_features_).most_common(30))\n",
        "\n",
        "print(\"\\nTop negative:\")\n",
        "print_state_features(Counter(crf.state_features_).most_common()[-30:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_X3ylJV57ba"
      },
      "source": [
        "\n",
        "\n",
        "Some observations: (from previous runs, more iterations)\n",
        "\n",
        "   * the model remembered names of some entities - maybe it is overfit, or maybe our features are not adequate, or maybe remembering is indeed helpful;\n",
        "   * \"calle\" is a street in Spanish; model learns that if a previous word was \"calle\" then the token is likely a part of location;\n",
        "   *  UPPERCASED or TitleCased words are likely entities of some kind;\n",
        "   * proper nouns (NP is a proper noun in the Spanish tagset) are often entities.\n",
        "\n",
        "What to do next\n",
        "\n",
        "    * Load 'testa' Spanish data.\n",
        "    * Use it to develop better features and to find best model parameters.\n",
        "    * Apply the model to 'testb' data again.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh-J9R_mJOvY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBw0VK7657ba"
      },
      "source": [
        "#krosswalidacja\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy\n",
        "\n",
        "A = numpy.array([[1, 2], [3, 4], [1, 2], [3, 4], [5,6],[7,8]])\n",
        "b = numpy.array([1, 2, 3, 4,5,6])\n",
        "kf = KFold(n_splits=3)\n",
        "kf.get_n_splits(A)\n",
        "print(kf)\n",
        "#KFold(n_splits=2, random_state=None, shuffle=False)\n",
        "for train_index, test_index in kf.split(A):\n",
        "     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "     b_train, b_test = b[train_index], b[test_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAZuppqURoWO"
      },
      "source": [
        "kf = KFold(n_splits=3)\n",
        "kf.get_n_splits(X_train)\n",
        "y_pred_all=[]\n",
        "for train_index, test_index in kf.split(X_train):\n",
        "    X_tr, X_tst = numpy.array(X_train)[train_index], numpy.array(X_train)[test_index]\n",
        "    y_tr, y_tst = numpy.array(y_train)[train_index], numpy.array(y_train)[test_index]\n",
        "    #print(train_index[1])\n",
        "    #print(X_train[test_index[0]])\n",
        "    crf.fit(X_tr, y_tr)\n",
        "    y_pred = crf.predict(X_tst)\n",
        "    #print(\"fold\")\n",
        "    #print(metrics.flat_classification_report(y_tst, y_pred, labels=sorted_labels, digits=3))\n",
        "    y_pred_all.extend(y_pred)\n",
        "print(\"all results\")\n",
        "print(metrics.flat_classification_report(y_train, y_pred_all, labels=sorted_labels, digits=3))\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycRGRSiuu6Es"
      },
      "source": [
        "Budowa końcowego modelu na całych danych treningowych i testowanie na danych testowych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yB6zP7EdXxL"
      },
      "source": [
        "crf.fit(X_train, y_train)\n",
        "y_pred = crf.predict(X_test)\n",
        "print(\"wynik na danych testowych\")\n",
        "print(metrics.flat_classification_report(y_test, y_pred, labels=sorted_labels, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ys7lxWoEJ8e"
      },
      "source": [
        "#Zadanie: \n",
        "\n",
        "\n",
        "1. Znajdz najlepsze rozwiązanie (skup sie na wyborze cech, a nie optymalizacji parametrów) dla zbioróe traina i testa\n"
      ]
    }
  ]
}